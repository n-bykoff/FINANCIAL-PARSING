{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC EDGAR PARSER\n",
    "\n",
    "### Description\n",
    "blah blah blah ( I'll fill it out later )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tickers and CIK-keys\n",
    "\n",
    "#### If you haven't tickers_and_cik.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Screener tests.xlsx')\n",
    "top_data = data[data['Cap M$'] != 'No data on finviz'][:100]\n",
    "tickers = list(top_data['Все'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_dic = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    \n",
    "    url = f'https://sec.report/Ticker/{ticker}/'\n",
    "    \n",
    "    request = requests.get(url, headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36'\n",
    "      })\n",
    "    content = request.content\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(content, 'html')\n",
    "        cik = soup.find('h2').text\n",
    "        cik_dic[ticker] = cik.split(' ')[2]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cik_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have tickers_and_cik.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_dic = {}\n",
    "\n",
    "with open('tickers_and_cik.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        cik_dic[line.split(' ')[0]] = line.split(' ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': '0000320193',\n",
       " 'MSFT': '0000789019',\n",
       " 'AMZN': '0001018724',\n",
       " 'GOOG': '0001652044',\n",
       " 'GOOGL': '0001652044',\n",
       " 'TSLA': '0001318605',\n",
       " 'FB': '0001326801',\n",
       " 'BABA': '0001577552',\n",
       " 'BRK-B': '0001067983',\n",
       " 'BRK-A': '0001067983',\n",
       " 'TSM': '0001046179',\n",
       " 'V': '0001403161',\n",
       " 'JPM': '0000019617',\n",
       " 'JNJ': '0000200406',\n",
       " 'WMT': '0000104169',\n",
       " 'PG': '0000080424',\n",
       " 'UNH': '0000731766',\n",
       " 'NVDA': '0001045810',\n",
       " 'MA': '0001141391',\n",
       " 'DIS': '0001744489',\n",
       " 'BAC': '0000070858',\n",
       " 'HD': '0000354950',\n",
       " 'PYPL': '0001633917',\n",
       " 'TM': '0001094517',\n",
       " 'INTC': '0000050863',\n",
       " 'VZ': '0000732712',\n",
       " 'NVS': '0001114448',\n",
       " 'ASML': '0000937966',\n",
       " 'CMCSA': '0001166691',\n",
       " 'NKE': '0000320187',\n",
       " 'ADBE': '0000796343',\n",
       " 'NFLX': '0001065280',\n",
       " 'XOM': '0000034088',\n",
       " 'KO': '0000021344',\n",
       " 'T': '0000732717',\n",
       " 'MRK': '0000310158',\n",
       " 'PDD': '0001737806',\n",
       " 'PFE': '0000078003',\n",
       " 'CRM': '0001108524',\n",
       " 'ABBV': '0001551152',\n",
       " 'TMO': '0000097745',\n",
       " 'PEP': '0000077476',\n",
       " 'ABT': '0000001800',\n",
       " 'CSCO': '0000858877',\n",
       " 'AVGO': '0001730168',\n",
       " 'CVX': '0000093410',\n",
       " 'QCOM': '0000804328',\n",
       " 'ORCL': '0001341439',\n",
       " 'LLY': '0000059478',\n",
       " 'ACN': '0001467373',\n",
       " 'BBL': '0001171264',\n",
       " 'BHP': '0000811809',\n",
       " 'DHR': '0000313616',\n",
       " 'NEE': '0000753308',\n",
       " 'COST': '0000909832',\n",
       " 'MDT': '0001613103',\n",
       " 'TXN': '0000097476',\n",
       " 'UL': '0000217410',\n",
       " 'SAP': '0001000184',\n",
       " 'MCD': '0000063908',\n",
       " 'TMUS': '0001283699',\n",
       " 'BMY': '0000014272',\n",
       " 'LFC': '0001268896',\n",
       " 'HON': '0000773840',\n",
       " 'UNP': '0000100885',\n",
       " 'SHOP': '0001594805',\n",
       " 'C': '0000831001',\n",
       " 'WFC': '0000072971',\n",
       " 'JD': '0001549802',\n",
       " 'UPS': '0001090727',\n",
       " 'AMGN': '0000318154',\n",
       " 'RIO': '0000863064',\n",
       " 'MS': '0000895421',\n",
       " 'LIN': '0001707925',\n",
       " 'HDB': '0001144967',\n",
       " 'AZN': '0000901832',\n",
       " 'SNE': '0000313838',\n",
       " 'NVO': '0000353278',\n",
       " 'PM': '0001413329',\n",
       " 'LOW': '0000060667',\n",
       " 'CHTR': '0001091667',\n",
       " 'SNY': '0001121404',\n",
       " 'TOT': '0000879764',\n",
       " 'RY': '0001000275',\n",
       " 'SBUX': '0000829224',\n",
       " 'BA': '0000012927',\n",
       " 'BUD': '0001668717',\n",
       " 'SE': '0001703399',\n",
       " 'PTR': '0001108329',\n",
       " 'IBM': '0000051143',\n",
       " 'BLK': '0001364742',\n",
       " 'HSBC': '0001089113',\n",
       " 'ZM': '0001585521',\n",
       " 'SCHW': '0000316709',\n",
       " 'AMD': '0000002488',\n",
       " 'ABNB': '0001559720',\n",
       " 'TD': '0000947263',\n",
       " 'RTX': '0000101829'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for downloading reports and making URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_reports(ticker, report_type, num_of_reports):\n",
    "    dl = Downloader('./')\n",
    "    dl.get(report_type, ticker, num_of_reports)\n",
    "    \n",
    "    path = f'./sec_edgar_filings/{ticker}/{report_type}'\n",
    "    list_of_files = os.walk(path)\n",
    "    list_of_files = list(list_of_files)[0][2]\n",
    "    shutil.rmtree(path)\n",
    "    \n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_urls(list_of_files, CIK):\n",
    "    base_url = r\"https://www.sec.gov/Archives/edgar/data/\"\n",
    "    hrefs = []\n",
    "    \n",
    "    for file in list_of_files:\n",
    "        hrefs.append(base_url + CIK + '/' + file.replace('-','').replace('.htm','/index.json').replace('.txt','/index.json'))\n",
    "    \n",
    "    return hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xml_urls(json_urls):\n",
    "    base_url = r\"https://www.sec.gov\"\n",
    "    \n",
    "    new_urls = []\n",
    "\n",
    "    for url in json_urls:\n",
    "        content = requests.get(url).json()\n",
    "\n",
    "        for file in content['directory']['item']:\n",
    "            if file['name'] == 'FilingSummary.xml':\n",
    "                xml_summary = base_url + content['directory']['name'] + \"/\" + file['name']\n",
    "                new_urls.append(xml_summary)\n",
    "    \n",
    "    return new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_urls(xml_summary):\n",
    "    base_url = xml_summary.replace('FilingSummary.xml', '')\n",
    "\n",
    "    content = requests.get(xml_summary).content\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    reports = soup.find('myreports')\n",
    "\n",
    "    master_reports = []\n",
    "\n",
    "    for report in reports.find_all('report')[:-1]:\n",
    "\n",
    "        report_dict = {}\n",
    "        report_dict['name_short'] = report.shortname.text\n",
    "        report_dict['url'] = base_url + report.htmlfilename.text\n",
    "\n",
    "        master_reports.append(report_dict)\n",
    "        \n",
    "    return master_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_statements_data(statements_url):\n",
    "    \n",
    "    statements_data = []\n",
    "\n",
    "    for statement in statements_url:\n",
    "\n",
    "        statement_data = {}\n",
    "        statement_data['headers'] = []\n",
    "        statement_data['sections'] = []\n",
    "        statement_data['data'] = []\n",
    "\n",
    "        content = requests.get(statement).content\n",
    "        report_soup = BeautifulSoup(content, 'html')\n",
    "\n",
    "        for index, row in enumerate(report_soup.table.find_all('tr')):\n",
    "\n",
    "            cols = row.find_all('td')\n",
    "\n",
    "            if (len(row.find_all('th')) == 0 and len(row.find_all('strong')) == 0): \n",
    "                reg_row = [ele.text.strip() for ele in cols]\n",
    "                statement_data['data'].append(reg_row)\n",
    "            elif (len(row.find_all('th')) == 0 and len(row.find_all('strong')) != 0):\n",
    "                sec_row = cols[0].text.strip()\n",
    "                statement_data['sections'].append(sec_row)\n",
    "            elif (len(row.find_all('th')) != 0):            \n",
    "                hed_row = [ele.text.strip() for ele in row.find_all('th')]\n",
    "                statement_data['headers'].append(hed_row)\n",
    "            else:            \n",
    "                print('We encountered an error.')\n",
    "\n",
    "        statements_data.append(statement_data)\n",
    "        \n",
    "    return statements_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_report(i, statements_data):\n",
    "    \n",
    "    if len(statements_data[i]['headers']) > 1:\n",
    "        income_header = statements_data[i]['headers'][1]\n",
    "    else:\n",
    "        income_header = statements_data[i]['headers'][0][1:]\n",
    "    \n",
    "    income_data = statements_data[i]['data']\n",
    "\n",
    "    income_df = pd.DataFrame(income_data)\n",
    "\n",
    "    income_df.index = income_df[0]\n",
    "    income_df.index.name = 'Category'\n",
    "    income_df = income_df.drop(0, axis = 1)\n",
    "\n",
    "    income_df = income_df.replace('[\\$,)]','', regex=True )\\\n",
    "                         .replace( '[(]','-', regex=True)\\\n",
    "                         .replace( '', 'NaN', regex=True)\n",
    "\n",
    "    income_df = income_df.astype(float)\n",
    "    income_df.columns = income_header\n",
    "    \n",
    "    return income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_data(all_master_reports):    \n",
    "    datas = []\n",
    "    statements_urls = []\n",
    "\n",
    "    for i in range(len(all_master_reports)):\n",
    "        for j in range(len(all_master_reports[i])):\n",
    "            if 'R2.htm' in all_master_reports[i][j]['url'] or 'statements of operation' in all_master_reports[i][j]['name_short'].lower():\n",
    "                statements_urls.append(all_master_reports[i][j]['url'])\n",
    "\n",
    "    statements_data = make_statements_data(statements_urls)\n",
    "\n",
    "    data = {}\n",
    "    for j in range(len(statements_data)):\n",
    "        key = all_master_reports[i][j]['name_short']\n",
    "        data[key] = make_df_from_report(j, statements_data)\n",
    "        df = data[key][:7]\n",
    "        df = df.T.groupby(level=0).first().T\n",
    "        datas.append(df)\n",
    "        \n",
    "    final_data = pd.concat(datas, axis=1)\n",
    "    final_data = final_data.sort_index(axis=1)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "AAPL - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MSFT - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "AMZN - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "GOOG - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "GOOGL - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "TSLA - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "FB - всё супер!\n",
      "BABA - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BRK-B - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BRK-A - ОШИБКА!\n",
      "TSM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "V - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "JPM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "JNJ - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "WMT - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "PG - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "UNH - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "NVDA - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MA - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "DIS - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BAC - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "HD - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "PYPL - всё супер!\n",
      "TM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "INTC - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "VZ - всё супер!\n",
      "NVS - ОШИБКА!\n",
      "ASML - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "CMCSA - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "NKE - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ADBE - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "NFLX - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "XOM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "KO - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "T - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MRK - всё супер!\n",
      "PDD - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "PFE - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "CRM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ABBV - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "TMO - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "PEP - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ABT - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "CSCO - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "AVGO - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "CVX - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "QCOM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ORCL - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "LLY - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ACN - ОШИБКА!\n",
      "BBL - ОШИБКА!\n",
      "BHP - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "DHR - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "NEE - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "COST - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MDT - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "TXN - всё супер!\n",
      "UL - ОШИБКА!\n",
      "SAP - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MCD - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "TMUS - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BMY - ОШИБКА!\n",
      "LFC - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "HON - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "UNP - всё супер!\n",
      "SHOP - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "C - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "WFC - ОШИБКА!\n",
      "JD - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "UPS - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "AMGN - всё супер!\n",
      "RIO - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "MS - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "LIN - ОШИБКА!\n",
      "HDB - ОШИБКА!\n",
      "AZN - ОШИБКА!\n",
      "SNE - ОШИБКА!\n",
      "NVO - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "PM - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "LOW - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "CHTR - всё супер!\n",
      "SNY - ОШИБКА!\n",
      "TOT - ОШИБКА!\n",
      "RY - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "SBUX - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BA - всё супер!\n",
      "BUD - ОШИБКА!\n",
      "SE - ОШИБКА!\n",
      "PTR - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "IBM - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "BLK - ОШИБКА!\n",
      "HSBC - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "ZM - всё супер!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "SCHW - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "AMD - ОШИБКА!\n",
      "ABNB - ОШИБКА!\n",
      "TD - ОШИБКА!\n",
      "list_of_files отработала\n",
      "json_urls отработала\n",
      "xml_urls отработала\n",
      "make_table_urls отработала\n",
      "RTX - ОШИБКА!\n"
     ]
    }
   ],
   "source": [
    "report_type = '10-Q'\n",
    "num_of_reports = 8\n",
    "\n",
    "os.mkdir('./tables_from_reports')\n",
    "\n",
    "for ticker, CIK in cik_dic.items():\n",
    "    try:\n",
    "        list_of_files = download_reports(ticker, report_type, num_of_reports)\n",
    "        print('list_of_files отработала')\n",
    "        json_urls = make_json_urls(list_of_files, CIK)\n",
    "        print('json_urls отработала')\n",
    "        xml_urls = make_xml_urls(json_urls)\n",
    "        print('xml_urls отработала')\n",
    " \n",
    "        all_master_reports = []\n",
    "        for url in xml_urls:\n",
    "            all_master_reports.append(make_table_urls(url))\n",
    "        print('make_table_urls отработала')\n",
    "        \n",
    "        final_data = make_final_data(all_master_reports)\n",
    "        final_data.to_excel(f'./tables_from_reports/{ticker}_last_{num_of_reports}_reports.xlsx')\n",
    "        print(f'{ticker} - всё супер!')\n",
    "    except:\n",
    "        print(f'{ticker} - ОШИБКА!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
